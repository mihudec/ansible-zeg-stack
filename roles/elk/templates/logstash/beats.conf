# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
#    ssl => true
#    ssl_certificate => "/etc/logstash/ls-01.crt"
#    ssl_key => "/etc/logstash/ls-01.pk8"
#    ssl_certificate_authorities => "/etc/logstash/CA_CHAIN.pem"
#    ssl_verify_mode => "none"
  }
}

filter {
  mutate {
    remove_field => ["agent", "@version", "ecs", "host", "input", "[log][offset]"]
    remove_tag => ["beats_input_codec_plain_applied"]
  }
  if "cisco" in [tags] {
    grok {
      # There are a couple of custom patterns associated with this filter.
      patterns_dir => [ "/usr/share/logstash/custom_plugins/patterns" ]

      match => [
        # Strip Syslog-NG 
        "message", "%{TIMESTAMP:log_timestamp} %{IPORHOST:log_host} %{GREEDYDATA:message}"
        
      ]

      overwrite => [ "message" ]

    } # grok

    date {
      match => [
          "log_timestamp",

          # Syslog-NG Default
          "MMM dd HH:mm:ss",
          "MMM  d HH:mm:ss",

          # Hail marry
          "ISO8601"
        ]
        target => ["@timestamp"]
        remove_field => ["log_timestamp"]
    } # date

  } # if
}

output {
  #file {
  #  path => "/tmp/test_beats_output"
  #  codec => rubydebug
  #}
  if "cisco" in [tags] {
    if "_grokparsefailure" not in [tags] {
      pipeline {
        send_to => cisco
      } # pipeline
    } else {
      file {
          path => "/tmp/beats_cisco_error"
        codec => rubydebug
      }
    } #if _grokparsefailure
  } # if cisco
  if "cisco_xr" in [tags] {
    pipeline {
      send_to => cisco
    }
  } # if cisco_xr
}

